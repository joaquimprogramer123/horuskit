<!DOCTYPE html>
<html lang="pt-BR">
<head>
    <meta charset="UTF-8">
    <title>Vídeo WebRTC Autoplay</title>
    <script src="https://webrtc.github.io/adapter/adapter-latest.js"></script>
    <script src="face-api.js-master/dist/face-api.js"></script>
</head>
<body>
    <h1>Vídeo WebRTC</h1>

    <div id="videoStream">
        <video id="myVideo" autoplay playsinline></video>
    </div>

    <!-- Carregando os modelos -->
    <script>
        // Carrega os modelos necessários e inicia o vídeo
        Promise.all([
            faceapi.nets.tinyFaceDetector.loadFromUri('/models'),
            faceapi.nets.faceLandmark68Net.loadFromUri('/models'),
            faceapi.nets.faceRecognitionNet.loadFromUri('/models')
        ]).then(startVideo);

        // Função para iniciar a câmera e transmitir o vídeo para o elemento de vídeo
        async function startVideo() {
            const video = document.getElementById('myVideo');
            try {
                // Solicitar permissão do usuário para acessar a câmera
                const stream = await navigator.mediaDevices.getUserMedia({ video: true });

                // Adicionar o fluxo de vídeo ao elemento de vídeo
                video.srcObject = stream;

                // Inicia a detecção de rostos a cada 100 milissegundos
                setInterval(detectAndCompareFaces, 1000);
            } catch (error) {
                console.error('Erro ao acessar a câmera: ', error);
                alert('Não foi possível acessar a câmera. Verifique se as permissões estão corretas.');
            }
        }

        // Função para detectar rostos e compará-los com as imagens no Firebase Storage
        async function detectAndCompareFaces() {
            const video = document.getElementById('myVideo');
            // Configuração para o detector de rostos
            const options = new faceapi.TinyFaceDetectorOptions();
            // Detecta rosto no vídeo com descritor de rosto
            const detection = await faceapi.detectSingleFace(video, options).withFaceLandmarks().withFaceDescriptor();
            if (detection) {
                const { box } = detection.detection;
                // Verifica se a bounding box é válida
                if (box && box.top !== null && box.bottom !== null) {
                    console.log('Bounding box válida:', box);
                    // Compara o rosto detectado com as imagens no Firebase Storage
                    await compareFaceWithStoredImages(detection.descriptor);
                } else {
                    console.error('Bounding box inválida:', box);
                }
            }
        }

        // Função para comparar o rosto detectado com as imagens no Firebase Storage
        async function compareFaceWithStoredImages(detectedFaceDescriptor) {
            // Recupera a referência do Firebase Storage
            const storageRef = firebase.storage().ref();

            try {
                // Recupera a lista de imagens salvas no Firebase Storage
                const imageList = await storageRef.listAll();
                
                // Itera sobre cada imagem na lista
                for (const imageRef of imageList.items) {
                    // Recupera a URL da imagem
                    const imageURL = await imageRef.getDownloadURL();
                    
                    // Carrega a imagem usando a face-api.js
                    const image = await faceapi.fetchImage(imageURL);
                    
                    // Detecta o rosto na imagem
                    const faceDetection = await faceapi.detectSingleFace(image).withFaceLandmarks().withFaceDescriptor();
                    
                    if (faceDetection) {
                        const { box } = faceDetection.detection;
                        // Verifica se a bounding box é válida
                        if (box && box.top !== null && box.bottom !== null) {
                            console.log('Bounding box válida na imagem:', box);
                            // Compara o rosto detectado com o rosto na imagem
                            const distance = faceapi.euclideanDistance(detectedFaceDescriptor, faceDetection.descriptor);
                            
                            // Define um limite de similaridade (ajuste conforme necessário)
                            const similarityThreshold = 0.6;
                            
                            // Verifica se a distância é menor que o limite de similaridade
                            if (distance < similarityThreshold) {
                                console.log(`Correspondência encontrada com ${imageRef.name}`);
                                // Faça o que for necessário quando encontrar uma correspondência
                            }
                        } else {
                            console.error('Bounding box inválida na imagem:', box);
                        }
                    }
                }
            } catch (error) {
                console.error('Erro ao comparar rostos:', error);
            }
        }
    </script>
</body>
</html>
