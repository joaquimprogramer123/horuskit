<!DOCTYPE html>
<html lang="pt-BR">
<head>
    <meta charset="UTF-8">
    <script src="https://webrtc.github.io/adapter/adapter-latest.js"></script>
    <script src="face-api.js-master/dist/face-api.js"></script>
    <style>
        #videoStream {
            position: relative;
        }
        canvas {
            position: absolute;
            top: 0;
            left: 0;
        }
    </style>
</head>
<body>

<!-- Instancia para importar as bibliotecas do firebase namespace-->

<script src="https://www.gstatic.com/firebasejs/10.9.0/firebase-app-compat.js"></script>
<script src="https://www.gstatic.com/firebasejs/10.9.0/firebase-storage-compat.js"></script>

    

     <!-- Intancia para conectar com o firebase-->

    <script type="module">
  // Import the functions you need from the SDKs you need
  import { initializeApp } from "https://www.gstatic.com/firebasejs/10.12.0/firebase-app.js";
  import { getAnalytics } from "https://www.gstatic.com/firebasejs/10.12.0/firebase-analytics.js";
  // TODO: Add SDKs for Firebase products that you want to use
  // https://firebase.google.com/docs/web/setup#available-libraries

  // Your web app's Firebase configuration
  // For Firebase JS SDK v7.20.0 and later, measurementId is optional
  const firebaseConfig = {
    apiKey: "AIzaSyAdVrAXk70WCDvw6nveao9SwCAAAbIpsts",
    authDomain: "horus-87f81.firebaseapp.com",
    projectId: "horus-87f81",
    storageBucket: "horus-87f81.appspot.com",
    messagingSenderId: "692067844473",
    appId: "1:692067844473:web:1a18ba28a30c0f48332fa8",
    measurementId: "G-FR49ZZTE4E"
  };

  // Initialize Firebase
  const app = initializeApp(firebaseConfig);
  const analytics = getAnalytics(app);
</script>


    
    <h1>Vídeo WebRTC</h1>

    <div id="videoStream">
        <video id="myVideo" autoplay playsinline></video>
        <canvas id="overlay"></canvas>
    </div>

    
    <script type="module">

    // TODO: Replace the following with your app's Firebase project configuration
    // See: https://firebase.google.com/docs/web/learn-more#config-object
    const firebaseConfig = {
        apiKey: "AIzaSyAdVrAXk70WCDvw6nveao9SwCAAAbIpsts",
        authDomain: "horus-87f81.firebaseapp.com",
        projectId: "horus-87f81",
        storageBucket: "horus-87f81.appspot.com",
        messagingSenderId: "692067844473",
        appId: "1:692067844473:web:1a18ba28a30c0f48332fa8",
        measurementId: "G-FR49ZZTE4E"
    };

    // Initialize Firebase
    firebase.initializeApp(firebaseConfig);

        // Carrega os modelos necessários e inicia o vídeo
        Promise.all([
            faceapi.nets.tinyFaceDetector.loadFromUri('/models'),
            faceapi.nets.faceLandmark68Net.loadFromUri('/models'),
            faceapi.nets.faceRecognitionNet.loadFromUri('/models')
        ]).then(startVideo);

        // Função para iniciar a câmera e transmitir o vídeo para o elemento de vídeo
        async function startVideo() {
            const video = document.getElementById('myVideo');
            const canvas = document.getElementById('overlay');
            try {
                // Solicitar permissão do usuário para acessar a câmera
                const stream = await navigator.mediaDevices.getUserMedia({ video: true });

                // Adicionar o fluxo de vídeo ao elemento de vídeo
                video.srcObject = stream;

                // Redimensionar o canvas para corresponder ao tamanho do vídeo
                video.addEventListener('play', () => {
                    canvas.width = video.videoWidth;
                    canvas.height = video.videoHeight;
                });

                // Inicia a detecção de rostos a cada 1000 milissegundos
                setInterval(() => detectAndCompareFaces(video, canvas), 1000);
            } catch (error) {
                console.error('Erro ao acessar a câmera: ', error);
                alert('Não foi possível acessar a câmera. Verifique se as permissões estão corretas.');
            }
        }

        // Função para detectar rostos e compará-los com as imagens no Firebase Storage
        async function detectAndCompareFaces(video, canvas) {
            // Configuração para o detector de rostos
            const options = new faceapi.TinyFaceDetectorOptions({ inputSize: 128, scoreThreshold: 0.5 });
            try {
                // Detecta rosto no vídeo com descritor de rosto
                const detection = await faceapi.detectSingleFace(video, options).withFaceLandmarks().withFaceDescriptor();
                if (detection) {
                    const { box } = detection.detection;
                    // Verifica se a bounding box é válida
                    if (box && box.top !== null && box.bottom !== null && box.left !== null && box.right !== null) {
                        console.log('Bounding box válida:', box);
                        // Desenhar a bounding box no canvas
                        const dims = faceapi.matchDimensions(canvas, video, true);
                        const resizedDetections = faceapi.resizeResults(detection, dims);
                        faceapi.draw.drawDetections(canvas, resizedDetections);

                        // Compara o rosto detectado com as imagens no Firebase Storage
                        await compareFaceWithStoredImages(detection.descriptor);
                    } else {
                        console.error('Bounding box inválida:', box);
                    }
                }
            } catch (error) {
                console.error('Erro ao detectar rosto:', error);
            }
        }

  async function compareFaceWithStoredImages(detectedFaceDescriptor) {
    const storageRef = firebase.storage().ref();
    let matchFound = false;  // Variável para rastrear se uma correspondência foi encontrada

    try {
        // Recupera a lista de imagens salvas no Firebase Storage
        const imageList = await storageRef.listAll();
        
        // Itera sobre cada imagem na lista
        for (const imageRef of imageList.items) {
            // Recupera a URL da imagem
            const imageURL = await imageRef.getDownloadURL();
            
            // Carrega a imagem usando a face-api.js
            const image = await faceapi.fetchImage(imageURL);
            
            // Detecta o rosto na imagem
            const faceDetection = await faceapi.detectSingleFace(image).withFaceLandmarks().withFaceDescriptor();
            
            if (faceDetection) {
                // Compara o rosto detectado com o rosto na imagem
                const distance = faceapi.euclideanDistance(detectedFaceDescriptor, faceDetection.descriptor);
                
                // Define um limite de similaridade (ajuste conforme necessário)
                const similarityThreshold = 0.6;
                
                // Verifica se a distância é menor que o limite de similaridade
                if (distance < similarityThreshold) {
                    console.log(`Correspondência encontrada com ${imageRef.name}`);
                    matchFound = true;
                    break;  // Sai do loop pois uma correspondência já foi encontrada
                }
            }
        }

        // Após verificar todas as imagens, redireciona conforme o resultado da busca
        if (matchFound) {
            window.location.href = 'autorizado.html';  // Redireciona para a página autorizado.html
        } else {
            window.location.href = 'negado.html';  // Redireciona para a página negado.html
        }
    } catch (error) {
        console.error('Erro ao comparar rostos:', error);
        window.location.href = 'negado.html';  // Em caso de erro, considera como não autorizado
    }
}



    
    </script>
</body>
</html>
