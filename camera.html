<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Camera with Face Recognition</title>
    <script src="https://cdn.jsdelivr.net/npm/@vladmandic/face-api/dist/face-api.min.js"></script>
</head>
<style type="text/css">
    body {
        margin: 0;
        overflow: hidden;
    }
    #video {
        position: absolute;
        top: 0;
        left: 0;
        width: 100%;
        height: 100%;
        object-fit: cover; /* Cobertura total preservando proporção */
    }
    canvas {
        position: absolute;
        top: 0;
        left: 0;
    }
</style>
<body>
    <video id="video" autoplay playsinline></video>
    <canvas id="canvas"></canvas>
    <script type="text/javascript">
        // Função para iniciar a câmera
        async function startCamera() {
            const constraints = {
                video: {
                    facingMode: 'user' // Use 'environment' for back camera
                }
            };
            try {
                const stream = await navigator.mediaDevices.getUserMedia(constraints);
                const video = document.getElementById('video');
                video.srcObject = stream;
            } catch (error) {
                console.error('Error accessing the camera', error);
            }
        }

        // Função para iniciar a detecção de faces
        async function startFaceDetection() {
            await faceapi.nets.tinyFaceDetector.loadFromUri('/models');
            await faceapi.nets.faceLandmark68Net.loadFromUri('/models');
            await faceapi.nets.faceExpressionNet.loadFromUri('/models');

            const video = document.getElementById('video');
            const canvas = document.getElementById('canvas');
            const displaySize = { width: video.width, height: video.height };
            faceapi.matchDimensions(canvas, displaySize);

            video.addEventListener('play', () => {
                setInterval(async () => {
                    const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions())
                        .withFaceLandmarks()
                        .withFaceExpressions();
                    const resizedDetections = faceapi.resizeResults(detections, displayLocation);
                    canvas.getContext('2d').clearRect(0, 0, canvas.width, canvas.height);
                    faceapi.draw.drawDetections(canvas, resizedDetections);
                    faceapi.draw.drawFaceLandmarks(canvas, resizedDetections);
                    faceapi.draw.drawFaceExpressions(canvas, resizedDetections);
                }, 100);
            });
        }

        // Listener para quando o conteúdo estiver carregado
        document.addEventListener('DOMContentLoaded', (event) => {
            startCamera().then(startFaceDetection);
        });
    </script>
</body>
</html>


